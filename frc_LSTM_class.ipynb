{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "import natasha\n",
    "import mlflow\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "import psycopg2\n",
    "from torchinfo import summary\n",
    "from datetime import datetime\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "DB_HOST = os.environ.get(\"DB_HOST\")\n",
    "DB_PORT = os.environ.get(\"DB_PORT\")\n",
    "DB_USER = os.environ.get(\"DB_USER\")\n",
    "DB_PASS = os.environ.get(\"DB_PASS\")\n",
    "DB_NAME = os.environ.get(\"DB_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.strptime(\"2024-01-09 00:00:00\", \"%Y-%d-%m %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_config, device, TRAIN_LOADER, TEST_LOADER,\n",
    "                model = None, optimizer = None, scheduler = None,\n",
    "                weight_decay = 1e-3,\n",
    "                lr = 1e-3,\n",
    "                start_epoch = 0,\n",
    "                epochs = 10):\n",
    "    try:\n",
    "        if model == None:\n",
    "            model = Forecaster(model_config).to(device)\n",
    "        if optimizer == None:\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        if scheduler is not None:\n",
    "            scheduler = StepLR(optimizer, step_size=scheduler[\"step_size\"], gamma=scheduler[\"gamma\"])\n",
    "        with open(\"artifacts/model_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(str(summary(model)))\n",
    "        mlflow.log_artifacts(\"artifacts\")\n",
    "        BCE = nn.BCELoss()\n",
    "        for ep in tqdm(range(start_epoch, start_epoch + epochs)):\n",
    "            epoch_loss_train = 0; epoch_loss_test = 0\n",
    "            accuracy_train = 0; accuracy_test = 0\n",
    "            # TRAIN\n",
    "            for sample in tqdm(TRAIN_LOADER, desc = f\"Epoch: {ep}\"):\n",
    "                X_time_ = sample[0].to(device); Add_feature_ts_ = sample[1].to(device); ticker=sample[2].to(device); Y_ = sample[3].to(device)\n",
    "                pred = model(\n",
    "                    time = X_time_,\n",
    "                    add_time = Add_feature_ts_,\n",
    "                    ticker=ticker\n",
    "                ).reshape([-1])\n",
    "                loss_train = BCE(pred, Y_.type(torch.float))\n",
    "                optimizer.zero_grad()\n",
    "                loss_train.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss_train += loss_train.item() * len(pred)\n",
    "                accuracy_train += pred.round().int().eq(Y_).sum().item()\n",
    "            # TEST\n",
    "            for sample in tqdm(TEST_LOADER, desc = f\"Epoch: {ep}\"):\n",
    "                X_time_ = sample[0].to(device); Add_feature_ts_ = sample[1].to(device); ticker=sample[2].to(device); Y_ = sample[3].to(device)\n",
    "                with torch.no_grad():\n",
    "                    pred = model(\n",
    "                        time = X_time_,\n",
    "                        add_time = Add_feature_ts_,\n",
    "                        ticker=ticker\n",
    "                    ).reshape([-1])\n",
    "                loss_test = BCE(pred, Y_.type(torch.float))\n",
    "                epoch_loss_test += loss_test.item() * len(pred)\n",
    "                accuracy_test += pred.round().int().eq(Y_).sum().item()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            accuracy_train /= len(TRAIN_LOADER.dataset); accuracy_test /= len(TEST_LOADER.dataset)\n",
    "            mlflow.log_metrics({\"train loss\":epoch_loss_train, \"test loss\":epoch_loss_test, \"train_acc\":accuracy_train, \"test_acc\":accuracy_test}, step=ep)\n",
    "            if ep % 10 == 0:\n",
    "                clear_output()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    except KeyboardInterrupt:\n",
    "        torch.save(model, \"model.pt\")\n",
    "        torch.save(optimizer.state_dict(), \"optimizer_state_dict.pt\")\n",
    "        print(\"save with error\")\n",
    "        return model, optimizer\n",
    "    finally:\n",
    "        torch.save(model, \"model.pt\")\n",
    "        torch.save(optimizer.state_dict(), \"optimizer_state_dict.pt\")\n",
    "        print(\"done\")\n",
    "        return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_to_np_time_seties(df_pd:pd.DataFrame, index_column_time=None, x_step=50, y_step=10, columns_x=[1, 2, 3, 4, 5], columns_y=[2, 3]) -> np.array:   \n",
    "    df_pd = df_pd.reset_index(drop=True)\n",
    "    if index_column_time != None:\n",
    "       time = df_pd.loc[:, index_column_time].copy()\n",
    "    \n",
    "    num_samples = df_pd.shape[0]\n",
    "    num_samples = np.floor(num_samples / (x_step+y_step)).astype(int)\n",
    "    y_features = len(columns_y)\n",
    "    x_features = len(columns_x)\n",
    "\n",
    "    \n",
    "\n",
    "    X, Y = np.empty((num_samples, x_step, x_features)), np.empty((num_samples, y_step, y_features))\n",
    "    if index_column_time != None:\n",
    "        T = np.empty((num_samples, 2), dtype=pd.Timestamp)\n",
    "\n",
    "    start_x = 0\n",
    "    start_y = x_step\n",
    "    for index in tqdm(range(0, num_samples)):\n",
    "        if df_pd.loc[start_x:start_x + x_step - 1, columns_x].shape[0] == 0:\n",
    "            print(df_pd.loc[start_x-60:start_x + x_step - 1, columns_x])\n",
    "            print('start, end', start_x, start_y)\n",
    "        X[index] = df_pd.loc[start_x:start_x + x_step - 1, columns_x].to_numpy().reshape((x_step, x_features))\n",
    "        \n",
    "        Y[index] = df_pd.loc[start_y:start_y + y_step - 1, columns_y].to_numpy().reshape((y_step, y_features))\n",
    "        \n",
    "        if index_column_time != None:\n",
    "            T[index] = [time.loc[start_x:start_x + x_step].min(), time.loc[start_x:start_x + x_step].max()]\n",
    "\n",
    "        start_x = start_x + x_step + y_step\n",
    "        start_y = start_y + x_step + y_step\n",
    "        \n",
    "    if index_column_time != None:\n",
    "        return X, Y, T\n",
    "    else:\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rsi(prices: torch.Tensor, period: int = 14):\n",
    "    \"\"\"\n",
    "    Вычисляет RSI для каждого временного ряда из батча.\n",
    "    prices: тензор размера [batch, seq_len]\n",
    "    Возвращает тензор RSI для последнего временного шага: [batch]\n",
    "    \"\"\"\n",
    "    # Вычисляем изменения цены\n",
    "    delta = prices[:, 1:] - prices[:, :-1]  # [batch, seq_len-1]\n",
    "    # Вычисляем прирост и потери\n",
    "    gain = torch.clamp(delta, min=0)\n",
    "    loss = torch.clamp(-delta, min=0)\n",
    "    \n",
    "    # Если шагов меньше, чем период, возвращаем NaN\n",
    "    if delta.shape[1] < period:\n",
    "        raise ValueError(\"Длина временного ряда меньше, чем период RSI\")\n",
    "    \n",
    "    # Усредняем приросты и потери по последнему периоду\n",
    "    avg_gain = gain[:, -period:].mean(dim=1)\n",
    "    avg_loss = loss[:, -period:].mean(dim=1)\n",
    "    \n",
    "    rs = avg_gain / (avg_loss + 1e-8)  # добавляем маленькое число, чтобы не делить на 0\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi  # [batch]\n",
    "\n",
    "def compute_ema(prices: torch.Tensor, period: int):\n",
    "    \"\"\"\n",
    "    Вычисляет EMA по заданному периоду для каждого временного ряда.\n",
    "    prices: тензор размера [batch, seq_len]\n",
    "    Возвращает EMA с той же размерностью [batch, seq_len].\n",
    "    \"\"\"\n",
    "    alpha = 2 / (period + 1)\n",
    "    ema = torch.zeros_like(prices)\n",
    "    ema[:, 0] = prices[:, 0]  # инициализация первым значением\n",
    "    # Итеративное вычисление EMA\n",
    "    for t in range(1, prices.shape[1]):\n",
    "        ema[:, t] = alpha * prices[:, t] + (1 - alpha) * ema[:, t-1]\n",
    "    return ema\n",
    "\n",
    "def compute_macd(prices: torch.Tensor, short_period: int = 5, long_period: int = 12, signal_period: int = 5):\n",
    "    \"\"\"\n",
    "    Вычисляет MACD, сигнальную линию и гистограмму для каждого временного ряда.\n",
    "    Из-за малого числа шагов в ряду (24 шага) стандартные периоды (12, 26, 9) могут быть не применимы.\n",
    "    Поэтому можно использовать меньшие периоды.\n",
    "    \"\"\"\n",
    "    ema_short = compute_ema(prices, short_period)\n",
    "    ema_long  = compute_ema(prices, long_period)\n",
    "    \n",
    "    # MACD как разница EMA короткого и длинного периодов\n",
    "    macd = ema_short - ema_long\n",
    "    \n",
    "    # Сигнальная линия – EMA от MACD\n",
    "    signal_line = compute_ema(macd, signal_period)\n",
    "    # Гистограмма – разница между MACD и сигнальной линией\n",
    "    histogram = macd - signal_line\n",
    "    return macd, signal_line, histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"SELECT * FROM price_hour\"\"\"\n",
    "with psycopg2.connect(dbname = DB_NAME, user = DB_USER, password = DB_PASS, host = DB_HOST, port = DB_PORT) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(query)\n",
    "        time_series = pd.DataFrame(cur.fetchall(), columns=[\"open\", \"low\", \"high\", \"close\", \"volume\", \"date\", \"ticker\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "time_series = time_series[time_series[\"date\"] <= current_date]\n",
    "tickers_ = np.array(['MGNT', 'PHOR', 'MAGN', 'VTBR', 'RUAL', 'ALRS', 'FLOT', 'TATN',\n",
    "       'RTKM', 'MTSS', 'NVTK', 'SNGS', 'ROSN', 'CHMF', 'KMAZ', 'YDEX',\n",
    "       'AFLT', 'SBER', 'MVID', 'MTLR', 'GAZP', 'LENT', 'BSPB', 'SIBN',\n",
    "       'HYDR', 'NLMK', 'RASP', 'GMKN', 'AFKS', 'PLZL', 'LKOH'],\n",
    "      dtype=object)\n",
    "\n",
    "\n",
    "time_series = time_series[time_series[\"ticker\"].isin(tickers_)]\n",
    "time_series.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series['weekday'] = time_series['date'].apply(lambda row: row.weekday()) + 1\n",
    "time_series['hour'] = time_series['date'].apply(lambda row: row.hour)\n",
    "time_series['hour_sin'] = np.sin(np.pi * 2 * time_series['hour'] / 24)\n",
    "time_series['hour_cos'] = np.cos(np.pi * 2 * time_series['hour'] / 24)\n",
    "time_series['weekday_sin'] = np.sin(np.pi * 2 * time_series['weekday'] / 7)\n",
    "time_series['weekday_cos'] = np.cos(np.pi * 2 * time_series['weekday'] / 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>weekday_sin</th>\n",
       "      <th>weekday_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5601.0</td>\n",
       "      <td>5601.0</td>\n",
       "      <td>5601.0</td>\n",
       "      <td>5601.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2021-08-30 09:00:00</td>\n",
       "      <td>MGNT</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5601.0</td>\n",
       "      <td>5578.5</td>\n",
       "      <td>5623.5</td>\n",
       "      <td>5590.0</td>\n",
       "      <td>38026</td>\n",
       "      <td>2021-08-30 10:00:00</td>\n",
       "      <td>MGNT</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5592.0</td>\n",
       "      <td>5558.0</td>\n",
       "      <td>5593.5</td>\n",
       "      <td>5577.5</td>\n",
       "      <td>26215</td>\n",
       "      <td>2021-08-30 11:00:00</td>\n",
       "      <td>MGNT</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5577.5</td>\n",
       "      <td>5557.5</td>\n",
       "      <td>5577.5</td>\n",
       "      <td>5561.5</td>\n",
       "      <td>14164</td>\n",
       "      <td>2021-08-30 12:00:00</td>\n",
       "      <td>MGNT</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5561.5</td>\n",
       "      <td>5544.0</td>\n",
       "      <td>5579.0</td>\n",
       "      <td>5560.0</td>\n",
       "      <td>18672</td>\n",
       "      <td>2021-08-30 13:00:00</td>\n",
       "      <td>MGNT</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380727</th>\n",
       "      <td>6131.0</td>\n",
       "      <td>6116.0</td>\n",
       "      <td>6132.0</td>\n",
       "      <td>6132.0</td>\n",
       "      <td>400</td>\n",
       "      <td>2024-08-31 19:00:00</td>\n",
       "      <td>LKOH</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>-9.659258e-01</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380728</th>\n",
       "      <td>6132.0</td>\n",
       "      <td>6124.0</td>\n",
       "      <td>6139.5</td>\n",
       "      <td>6133.0</td>\n",
       "      <td>281</td>\n",
       "      <td>2024-08-31 20:00:00</td>\n",
       "      <td>LKOH</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380729</th>\n",
       "      <td>6133.0</td>\n",
       "      <td>6112.5</td>\n",
       "      <td>6144.0</td>\n",
       "      <td>6120.0</td>\n",
       "      <td>719</td>\n",
       "      <td>2024-08-31 21:00:00</td>\n",
       "      <td>LKOH</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380730</th>\n",
       "      <td>6120.0</td>\n",
       "      <td>6119.0</td>\n",
       "      <td>6133.5</td>\n",
       "      <td>6122.5</td>\n",
       "      <td>245</td>\n",
       "      <td>2024-08-31 22:00:00</td>\n",
       "      <td>LKOH</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380731</th>\n",
       "      <td>6130.0</td>\n",
       "      <td>6115.0</td>\n",
       "      <td>6132.0</td>\n",
       "      <td>6129.0</td>\n",
       "      <td>166</td>\n",
       "      <td>2024-08-31 23:00:00</td>\n",
       "      <td>LKOH</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380732 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          open     low    high   close  volume                date ticker  \\\n",
       "0       5601.0  5601.0  5601.0  5601.0      13 2021-08-30 09:00:00   MGNT   \n",
       "1       5601.0  5578.5  5623.5  5590.0   38026 2021-08-30 10:00:00   MGNT   \n",
       "2       5592.0  5558.0  5593.5  5577.5   26215 2021-08-30 11:00:00   MGNT   \n",
       "3       5577.5  5557.5  5577.5  5561.5   14164 2021-08-30 12:00:00   MGNT   \n",
       "4       5561.5  5544.0  5579.0  5560.0   18672 2021-08-30 13:00:00   MGNT   \n",
       "...        ...     ...     ...     ...     ...                 ...    ...   \n",
       "380727  6131.0  6116.0  6132.0  6132.0     400 2024-08-31 19:00:00   LKOH   \n",
       "380728  6132.0  6124.0  6139.5  6133.0     281 2024-08-31 20:00:00   LKOH   \n",
       "380729  6133.0  6112.5  6144.0  6120.0     719 2024-08-31 21:00:00   LKOH   \n",
       "380730  6120.0  6119.0  6133.5  6122.5     245 2024-08-31 22:00:00   LKOH   \n",
       "380731  6130.0  6115.0  6132.0  6129.0     166 2024-08-31 23:00:00   LKOH   \n",
       "\n",
       "        weekday  hour      hour_sin  hour_cos  weekday_sin  weekday_cos  \n",
       "0             1     9  7.071068e-01 -0.707107     0.781831      0.62349  \n",
       "1             1    10  5.000000e-01 -0.866025     0.781831      0.62349  \n",
       "2             1    11  2.588190e-01 -0.965926     0.781831      0.62349  \n",
       "3             1    12  1.224647e-16 -1.000000     0.781831      0.62349  \n",
       "4             1    13 -2.588190e-01 -0.965926     0.781831      0.62349  \n",
       "...         ...   ...           ...       ...          ...          ...  \n",
       "380727        6    19 -9.659258e-01  0.258819    -0.781831      0.62349  \n",
       "380728        6    20 -8.660254e-01  0.500000    -0.781831      0.62349  \n",
       "380729        6    21 -7.071068e-01  0.707107    -0.781831      0.62349  \n",
       "380730        6    22 -5.000000e-01  0.866025    -0.781831      0.62349  \n",
       "380731        6    23 -2.588190e-01  0.965926    -0.781831      0.62349  \n",
       "\n",
       "[380732 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_step = 24\n",
    "y_step = 12\n",
    "x_column = ['open', 'low', 'high', 'close', 'volume', 'hour_sin', 'hour_cos', 'weekday_sin', 'weekday_cos']\n",
    "y_column = ['close']\n",
    "x_feature = len(x_column)\n",
    "y_feature = len(y_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_batch(time_series):\n",
    "    X_time = np.zeros((0, x_step, x_feature))\n",
    "    Y = np.zeros((0, y_step, y_feature))\n",
    "    T = np.zeros((0, 2))\n",
    "    TICK = np.empty((0))\n",
    "    for ticker in time_series['ticker'].unique():\n",
    "        X_time_, Y_, T_ = pd_to_np_time_seties(time_series[time_series['ticker'] == ticker], \n",
    "                                            index_column_time='date', \n",
    "                                            x_step=x_step, \n",
    "                                            y_step=y_step, \n",
    "                                            columns_x=x_column, \n",
    "                                            columns_y=y_column)\n",
    "        \n",
    "        X_time = np.concatenate((X_time, X_time_), axis=0)\n",
    "        Y = np.concatenate((Y, Y_), axis=0)\n",
    "        T = np.concatenate((T, T_), axis=0)\n",
    "        TICK = np.concatenate((TICK, np.array([ticker] * X_time_.shape[0])), axis=0)\n",
    "\n",
    "    X_time = torch.from_numpy(X_time).float()\n",
    "    Y = torch.from_numpy(Y).float()\n",
    "    if Y.shape[-1] == 1:\n",
    "        Y = Y.reshape([Y.shape[0], -1])\n",
    "\n",
    "    Y = ((Y - X_time[:, -1:, 3]) / X_time[:, -1:, 3]) > 0.01\n",
    "    Y = Y.sum(dim=1)\n",
    "    Y[Y !=0 ] = 1\n",
    "\n",
    "    X_time[:, :, :5] = torch.log10(X_time[:, :, :5])\n",
    "    X_time[X_time == -torch.inf] = 0\n",
    "\n",
    "    Add_feature_ts = torch.empty([X_time.shape[0], 5])\n",
    "    # rsi\n",
    "    Add_feature_ts[:, 0] = compute_rsi(X_time[:, :, 3])\n",
    "    # mean\n",
    "    Add_feature_ts[:, 1] = X_time[:, :, 3].mean(dim=1)\n",
    "    Add_feature_ts[:, 2] = X_time[:, :, 4].mean(dim=1)\n",
    "    # std\n",
    "    Add_feature_ts[:, 3] = X_time[:, :, 3].std(dim=1)\n",
    "    Add_feature_ts[:, 4] = X_time[:, :, 4].std(dim=1)\n",
    "\n",
    "    # macd, signal_line, histogram\n",
    "    macd, signal_line, histogram = compute_macd(X_time[:, :, 3], 3, 5, 4)\n",
    "    X_time = torch.cat([X_time, macd.unsqueeze(-1), signal_line.unsqueeze(-1), histogram.unsqueeze(-1)], dim=2)\n",
    "\n",
    "    return X_time, Add_feature_ts, TICK, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_date = np.sort(time_series[\"date\"].unique())\n",
    "sep_index = int(len(unique_date) * 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 309/309 [00:00<00:00, 1129.33it/s]\n",
      "100%|██████████| 308/308 [00:00<00:00, 1125.77it/s]\n",
      "100%|██████████| 309/309 [00:00<00:00, 1143.88it/s]\n",
      "100%|██████████| 298/298 [00:00<00:00, 1093.19it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 1141.72it/s]\n",
      "100%|██████████| 309/309 [00:00<00:00, 1096.18it/s]\n",
      "100%|██████████| 235/235 [00:00<00:00, 1108.38it/s]\n",
      "100%|██████████| 304/304 [00:00<00:00, 1136.25it/s]\n",
      "100%|██████████| 303/303 [00:00<00:00, 1144.66it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 1129.09it/s]\n",
      "100%|██████████| 308/308 [00:00<00:00, 1113.26it/s]\n",
      "100%|██████████| 303/303 [00:00<00:00, 1156.02it/s]\n",
      "100%|██████████| 309/309 [00:00<00:00, 1116.25it/s]\n",
      "100%|██████████| 310/310 [00:00<00:00, 1074.79it/s]\n",
      "100%|██████████| 221/221 [00:00<00:00, 995.50it/s] \n",
      "100%|██████████| 310/310 [00:00<00:00, 1052.56it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 1116.63it/s]\n",
      "100%|██████████| 310/310 [00:00<00:00, 1086.01it/s]\n",
      "100%|██████████| 264/264 [00:00<00:00, 1178.57it/s]\n",
      "100%|██████████| 270/270 [00:00<00:00, 1088.29it/s]\n",
      "100%|██████████| 310/310 [00:00<00:00, 1091.55it/s]\n",
      "100%|██████████| 160/160 [00:00<00:00, 1062.21it/s]\n",
      "100%|██████████| 220/220 [00:00<00:00, 1145.77it/s]\n",
      "100%|██████████| 267/267 [00:00<00:00, 1070.89it/s]\n",
      "100%|██████████| 297/297 [00:00<00:00, 1162.32it/s]\n",
      "100%|██████████| 309/309 [00:00<00:00, 1137.05it/s]\n",
      "100%|██████████| 228/228 [00:00<00:00, 1222.60it/s]\n",
      "100%|██████████| 305/305 [00:00<00:00, 1146.05it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 1199.96it/s]\n",
      "100%|██████████| 306/306 [00:00<00:00, 1192.70it/s]\n",
      "100%|██████████| 309/309 [00:00<00:00, 1080.19it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 1152.22it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 1081.65it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 1081.64it/s]\n",
      "100%|██████████| 51/51 [00:00<00:00, 1186.09it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 1204.44it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 1218.44it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 1275.43it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 1227.28it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 1232.58it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 1214.79it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 1257.19it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 1261.96it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 1285.72it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 1255.84it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 1208.06it/s]\n",
      "100%|██████████| 36/36 [00:00<00:00, 1261.37it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 1148.94it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 1255.79it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 1245.31it/s]\n",
      "100%|██████████| 52/52 [00:00<00:00, 1279.72it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 1285.71it/s]\n",
      "100%|██████████| 48/48 [00:00<00:00, 1243.75it/s]\n",
      "100%|██████████| 52/52 [00:00<00:00, 1238.10it/s]\n",
      "100%|██████████| 52/52 [00:00<00:00, 1266.23it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 1232.59it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 1155.91it/s]\n",
      "100%|██████████| 52/52 [00:00<00:00, 1237.85it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 1255.79it/s]\n",
      "100%|██████████| 53/53 [00:00<00:00, 981.48it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 1227.27it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 1255.84it/s]\n"
     ]
    }
   ],
   "source": [
    "X_time_train, Add_feature_ts_train, TICK_train, Y_train = return_batch(time_series[time_series[\"date\"].isin(unique_date[:sep_index])])\n",
    "X_time_test, Add_feature_ts_test, TICK_test, Y_test = return_batch(time_series[time_series[\"date\"].isin(unique_date[sep_index:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(tickers_)\n",
    "TICK_train = torch.from_numpy(label_encoder.transform(TICK_train)).int()\n",
    "TICK_test = torch.from_numpy(label_encoder.transform(TICK_test)).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1]), tensor([5899, 3017]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1]), tensor([1225,  400]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_balance(Y):\n",
    "    indices_class_0 = torch.nonzero(Y == 0).squeeze()\n",
    "    indices_class_1 = torch.nonzero(Y == 1).squeeze()\n",
    "\n",
    "    class_sample = Y.unique(return_counts=True)[1].min().item()\n",
    "\n",
    "    torch.manual_seed(12312)\n",
    "    permuted_indices_class_0 = indices_class_0[torch.randperm(len(indices_class_0))][:class_sample]\n",
    "    torch.manual_seed(12312)\n",
    "    permuted_indices_class_1 = indices_class_1[torch.randperm(len(indices_class_1))][:class_sample]\n",
    "    permuted_indices = torch.cat([permuted_indices_class_0, permuted_indices_class_1])\n",
    "    return permuted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_balance = class_balance(Y_train)\n",
    "test_class_balance = class_balance(Y_test)\n",
    "X_time_train, Add_feature_ts_train, TICK_train, Y_train = X_time_train[train_class_balance], Add_feature_ts_train[train_class_balance], TICK_train[train_class_balance], Y_train[train_class_balance]\n",
    "X_time_test, Add_feature_ts_test, TICK_test, Y_test = X_time_test[test_class_balance], Add_feature_ts_test[test_class_balance], TICK_test[test_class_balance], Y_test[test_class_balance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_LOADER\n",
    "TRAIN_LOADER = TensorDataset(X_time_train, Add_feature_ts_train, TICK_train, Y_train)\n",
    "TEST_LOADER = TensorDataset(X_time_test, Add_feature_ts_test, TICK_test, Y_test)\n",
    "batch_size = 50\n",
    "TRAIN_LOADER = DataLoader(TRAIN_LOADER, batch_size=batch_size)\n",
    "TEST_LOADER = DataLoader(TEST_LOADER, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_experiment = \"LSTM_class\"\n",
    "\n",
    "class Forecaster(nn.Module):\n",
    "    def __init__(self, config_, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.config = {\n",
    "            \"x_feature\" : 4,\n",
    "            \"hidden_size\" : 36,\n",
    "            \"num_layers\" : 4,\n",
    "            \"n_add_feature_ts\" : 5,\n",
    "            \"y_feature\": 1,\n",
    "            \"n_ticker\":0,\n",
    "            \"ticker_embedd_dim\":0\n",
    "        }\n",
    "        if config_ != None:\n",
    "            for key in config_.keys():\n",
    "                self.config[key] = config_[key]\n",
    "        if config_[\"n_ticker\"] != 0:\n",
    "            self.ticker_embedd = nn.Embedding(config_[\"n_ticker\"], config_[\"ticker_embedd_dim\"])\n",
    "        self.lstm = nn.LSTM(self.config[\"x_feature\"], self.config[\"hidden_size\"], self.config[\"num_layers\"], batch_first=True)\n",
    "        n_feature = self.config[\"hidden_size\"] + self.config[\"n_add_feature_ts\"] + config_[\"ticker_embedd_dim\"]\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.LayerNorm(n_feature),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(n_feature, self.config[\"y_feature\"])\n",
    "        )\n",
    "\n",
    "    def forward(self, time:torch.Tensor, add_time:torch.Tensor=None, ticker:torch.Tensor=None, return_logit:bool=False):\n",
    "        h0 = torch.zeros(self.config[\"num_layers\"], time.size(0), self.config[\"hidden_size\"]).to(time.device)\n",
    "        c0 = torch.zeros(self.config[\"num_layers\"], time.size(0), self.config[\"hidden_size\"]).to(time.device)\n",
    "        out, _ = self.lstm(time, (h0, c0))\n",
    "        out = out[:, -1, :]\n",
    "        if self.config[\"n_add_feature_ts\"] != 0:\n",
    "            out = torch.cat([out, add_time], dim=1)\n",
    "        if self.config[\"n_ticker\"] != 0:\n",
    "            ticker_embedding = self.ticker_embedd(ticker)\n",
    "            out = torch.cat([out, ticker_embedding], dim=1)\n",
    "        out = self.fc(out)\n",
    "        if return_logit:\n",
    "            return out\n",
    "        else:\n",
    "            return torch.nn.functional.sigmoid(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/Stanislav/Documents/py/Data%20Science%20%28DS%29/dipom_pet/mlruns/181443399550379659', creation_time=1742792711462, experiment_id='181443399550379659', last_update_time=1742792711462, lifecycle_stage='active', name='LSTM_class', tags={}>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mlflow.set_experiment(name_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "        \"x_feature\" : X_time_train.shape[-1],\n",
    "        \"hidden_size\" : 36,\n",
    "        \"num_layers\" : 4,\n",
    "        \"n_add_feature_ts\" : Add_feature_ts_train.shape[-1],\n",
    "        \"y_feature\": 1,\n",
    "        \"n_ticker\":len(tickers_),\n",
    "        \"ticker_embedd_dim\":4\n",
    "        }\n",
    "# model_config= {\n",
    "#         \"attention_layer\" : 12,\n",
    "#         \"hidden_size\" : 36,\n",
    "#         \"num_heads\" : 4,\n",
    "#         \"x_feature\": X_time.shape[-1],\n",
    "#         \"x_step\": X_time.shape[1],\n",
    "#         \"y_step\": y_step,\n",
    "#         }\n",
    "\n",
    "scheduler = {\n",
    "    \"step_size\":100,\n",
    "    \"gamma\":0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1491: 100%|██████████| 121/121 [00:00<00:00, 236.77it/s]\n",
      "Epoch: 1491: 100%|██████████| 16/16 [00:00<00:00, 516.10it/s]\n",
      "Epoch: 1492: 100%|██████████| 121/121 [00:00<00:00, 249.69it/s]\n",
      "Epoch: 1492: 100%|██████████| 16/16 [00:00<00:00, 466.81it/s]\n",
      "Epoch: 1493: 100%|██████████| 121/121 [00:00<00:00, 255.39it/s]\n",
      "Epoch: 1493: 100%|██████████| 16/16 [00:00<00:00, 492.00it/s]\n",
      "Epoch: 1494: 100%|██████████| 121/121 [00:00<00:00, 256.82it/s]\n",
      "Epoch: 1494: 100%|██████████| 16/16 [00:00<00:00, 533.38it/s]\n",
      "Epoch: 1495: 100%|██████████| 121/121 [00:00<00:00, 234.52it/s]\n",
      "Epoch: 1495: 100%|██████████| 16/16 [00:00<00:00, 533.06it/s]\n",
      "Epoch: 1496: 100%|██████████| 121/121 [00:00<00:00, 251.32it/s]\n",
      "Epoch: 1496: 100%|██████████| 16/16 [00:00<00:00, 542.08it/s]\n",
      "Epoch: 1497: 100%|██████████| 121/121 [00:00<00:00, 232.02it/s]\n",
      "Epoch: 1497: 100%|██████████| 16/16 [00:00<00:00, 484.86it/s]\n",
      "Epoch: 1498: 100%|██████████| 121/121 [00:00<00:00, 251.48it/s]\n",
      "Epoch: 1498: 100%|██████████| 16/16 [00:00<00:00, 515.82it/s]\n",
      "Epoch: 1499: 100%|██████████| 121/121 [00:00<00:00, 252.37it/s]\n",
      "Epoch: 1499: 100%|██████████| 16/16 [00:00<00:00, 499.36it/s]\n",
      "100%|██████████| 1500/1500 [14:06<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Первый запуск\n",
    "try:\n",
    "    run = mlflow.start_run()\n",
    "    shutil.rmtree(\"artifacts/\", ignore_errors=True)\n",
    "    os.makedirs(\"artifacts/\", exist_ok=True)\n",
    "    with open(\"artifacts/model_config.json\", \"w\") as f:\n",
    "        json.dump(model_config, f)\n",
    "    model, optimizer = train_model(model_config, device, TRAIN_LOADER, TEST_LOADER,\n",
    "                                   epochs=1500, lr=1e-5, weight_decay=0)\n",
    "finally:\n",
    "    mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
