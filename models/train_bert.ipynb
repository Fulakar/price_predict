{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.amp import autocast, GradScaler\n",
    "from transformers import AutoTokenizer, LongformerConfig, LongformerForSequenceClassification, BertForSequenceClassification, BertConfig, BertModel\n",
    "from tqdm import tqdm\n",
    "import natasha\n",
    "from IPython.display import display, clear_output\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "sys.path.append(os.getcwd()[:-7])\n",
    "load_dotenv()\n",
    "DB_HOST = os.environ.get(\"DB_HOST\")\n",
    "DB_PORT = os.environ.get(\"DB_PORT\")\n",
    "DB_USER = os.environ.get(\"DB_USER\")\n",
    "DB_PASS = os.environ.get(\"DB_PASS\")\n",
    "DB_NAME = os.environ.get(\"DB_NAME\")\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_accuracy(pred:torch.Tensor, true:torch.Tensor):\n",
    "    return true.argmax(dim=1).eq(pred.argmax(dim=1)).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_clean(text: str, segmenter:natasha.Segmenter, word: str = None):\n",
    "    sentenses = []\n",
    "    doc = natasha.Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        for w in word:\n",
    "            if w in sent.text:\n",
    "                sentenses.append(sent.text)\n",
    "                break\n",
    "\n",
    "    sentenses = ' '.join(sentenses)\n",
    "    return sentenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM ticker_describe\"\n",
    "with psycopg2.connect(dbname = DB_NAME, user = DB_USER, password = DB_PASS, host = DB_HOST, port = DB_PORT) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(query)\n",
    "        ticker_describe = pd.DataFrame(cur.fetchall(), columns=[\"ticker\", \"sector\", \"name\", \"describe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at matvej-melikhov/ruBERT-finetuned-lenta and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"matvej-melikhov/ruBERT-finetuned-lenta\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = BertConfig.from_pretrained(model_name)\n",
    "model.max_position_embeddings = 1024\n",
    "model.num_labels = 3\n",
    "model.output_hidden_states = True\n",
    "model = BertForSequenceClassification(model)\n",
    "model_base = BertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "for name, param in model_base.named_parameters():\n",
    "    if 'position_embeddings' not in name:\n",
    "        model.state_dict()[name].copy_(param.data)\n",
    "\n",
    "model.bert.embeddings.position_embeddings.weight = torch.nn.Parameter(model_base.bert.embeddings.position_embeddings.weight.repeat([2, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final_2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>message</th>\n",
       "      <th>ticker</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-26 13:42:34+00:00</td>\n",
       "      <td>А акции Новатэка так вообще смогли закрыть утр...</td>\n",
       "      <td>новатэк</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-07 07:22:01+00:00</td>\n",
       "      <td>Объем торгов за первые 10 мин наглядно демонст...</td>\n",
       "      <td>газпром</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-08-27 20:59:11+00:00</td>\n",
       "      <td>Итак, на этой неделе акции Газпрома наконец-то...</td>\n",
       "      <td>газпром</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-08-24 08:04:25+00:00</td>\n",
       "      <td>​​Не один раз в этом году на всех уровнях я то...</td>\n",
       "      <td>газпром</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-08-20 09:37:02+00:00</td>\n",
       "      <td>Сегодня состоится последний визит в Москву Анг...</td>\n",
       "      <td>газпром</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>2022-01-14 14:03:01+00:00</td>\n",
       "      <td>Красноречивые обороты сегодня в Сбере. 72 млрд...</td>\n",
       "      <td>газпром</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>2022-01-17 19:56:42+00:00</td>\n",
       "      <td>​​По Сберу сформировался очень сильный уровень...</td>\n",
       "      <td>сбер</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>2022-01-18 19:19:44+00:00</td>\n",
       "      <td>​​Чем дальше в лес, тем больше дров! Сегодня о...</td>\n",
       "      <td>сбер</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>2022-02-25 08:34:58+00:00</td>\n",
       "      <td>На протяжении многих лет не один раз на рынке ...</td>\n",
       "      <td>сбер</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>2022-03-01 10:35:00+00:00</td>\n",
       "      <td>На фоне того, сколько сейчас стОят акции Сбера...</td>\n",
       "      <td>сбер</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2496 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           date  \\\n",
       "0     2021-11-26 13:42:34+00:00   \n",
       "1     2021-09-07 07:22:01+00:00   \n",
       "2     2021-08-27 20:59:11+00:00   \n",
       "3     2021-08-24 08:04:25+00:00   \n",
       "4     2021-08-20 09:37:02+00:00   \n",
       "...                         ...   \n",
       "2491  2022-01-14 14:03:01+00:00   \n",
       "2492  2022-01-17 19:56:42+00:00   \n",
       "2493  2022-01-18 19:19:44+00:00   \n",
       "2494  2022-02-25 08:34:58+00:00   \n",
       "2495  2022-03-01 10:35:00+00:00   \n",
       "\n",
       "                                                message   ticker sentiment  \\\n",
       "0     А акции Новатэка так вообще смогли закрыть утр...  новатэк  Positive   \n",
       "1     Объем торгов за первые 10 мин наглядно демонст...  газпром  Positive   \n",
       "2     Итак, на этой неделе акции Газпрома наконец-то...  газпром  Positive   \n",
       "3     ​​Не один раз в этом году на всех уровнях я то...  газпром  Positive   \n",
       "4     Сегодня состоится последний визит в Москву Анг...  газпром  Positive   \n",
       "...                                                 ...      ...       ...   \n",
       "2491  Красноречивые обороты сегодня в Сбере. 72 млрд...  газпром   Neutral   \n",
       "2492  ​​По Сберу сформировался очень сильный уровень...     сбер   Neutral   \n",
       "2493  ​​Чем дальше в лес, тем больше дров! Сегодня о...     сбер  Negative   \n",
       "2494  На протяжении многих лет не один раз на рынке ...     сбер  Negative   \n",
       "2495  На фоне того, сколько сейчас стОят акции Сбера...     сбер  Negative   \n",
       "\n",
       "      label  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "...     ...  \n",
       "2491      0  \n",
       "2492      0  \n",
       "2493      2  \n",
       "2494      2  \n",
       "2495      2  \n",
       "\n",
       "[2496 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_2 = pd.read_csv('data/final_2.csv').drop(columns=[\"Unnamed: 0\", \"idx\", \"channel_url\", \"views\", \"forwards\", \"entities\"]).rename(columns={\"tickers\":\"ticker\"})\n",
    "final_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cte = final_2[final_2[\"ticker\"].apply(lambda row: len(row.split(\" \"))) > 1]\n",
    "for row in cte.itertuples(index=False, name=None):\n",
    "    for ticker in row[2].split(\" \"):\n",
    "        final_2.loc[len(final_2)] = [row[0], row[1], ticker, row[3], row[4]]\n",
    "    \n",
    "final_2.drop(index=cte.index, inplace=True)\n",
    "final_2.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['новатэк', 'газпром', 'сбер', 'яндекс', 'лукойл', 'роснефть',\n",
       "       'магнит', 'северсталь', 'x5', 'нлмк', 'татнефть', 'норникель',\n",
       "       'фосагро', 'полиметалл', 'мтс', 'тинькофф', 'озон', 'втб',\n",
       "       'алроса', 'ростелеком', 'система', 'лента', 'уралкалий', 'россети',\n",
       "       'полюс'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_2.ticker.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_ticker(ticker):\n",
    "    norm = {\n",
    "        \"новатэк\":\"NVTK\", \"тинькофф\":\"T\",\n",
    "        \"газпром\":\"GAZP\", \"озон\":\"OZON\",\n",
    "        \"сбер\":\"SBER\", \"втб\":\"VTBR\",\n",
    "        \"яндекс\":\"YDEX\", \"алроса\":\"ALRS\",\n",
    "        \"лукойл\":\"LKOH\", \"ростелеком\":\"RTKM\",\n",
    "        \"роснефть\":\"ROSN\", \"система\":\"AFKS\",\n",
    "        \"магнит\":\"MGNT\", \"лента\":\"LENT\",\n",
    "        \"северсталь\":\"CHMF\", \"уралкалий\":\"URKAS\",\n",
    "        \"x5\":'X5', \"россети\":\"MSRS\",\n",
    "        \"нлмк\":\"NLMK\", \"полюс\":\"PLZL\",\n",
    "        \"татнефть\":\"TATN\", \"мтс\":\"MTSS\",\n",
    "        \"норникель\":\"GMKN\", \"полиметалл\":\"POLY\",\n",
    "        \"фосагро\":\"PHOR\"\n",
    "    }\n",
    "    return norm.get(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_2[\"ticker\"] = final_2[\"ticker\"].apply(rename_ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_2 = pd.merge(final_2, ticker_describe, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>message</th>\n",
       "      <th>ticker</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>sector</th>\n",
       "      <th>name</th>\n",
       "      <th>describe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-26 13:42:34+00:00</td>\n",
       "      <td>А акции Новатэка так вообще смогли закрыть утр...</td>\n",
       "      <td>NVTK</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>Энергетика</td>\n",
       "      <td>НОВАТЭК</td>\n",
       "      <td>НОВАТЭК — крупнейший независимый производитель...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-07 07:22:01+00:00</td>\n",
       "      <td>Объем торгов за первые 10 мин наглядно демонст...</td>\n",
       "      <td>GAZP</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>Энергетика</td>\n",
       "      <td>Газпром</td>\n",
       "      <td>«Газпром» — глобальная энергетическая компания...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-08-27 20:59:11+00:00</td>\n",
       "      <td>Итак, на этой неделе акции Газпрома наконец-то...</td>\n",
       "      <td>GAZP</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>Энергетика</td>\n",
       "      <td>Газпром</td>\n",
       "      <td>«Газпром» — глобальная энергетическая компания...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-08-24 08:04:25+00:00</td>\n",
       "      <td>​​Не один раз в этом году на всех уровнях я то...</td>\n",
       "      <td>GAZP</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>Энергетика</td>\n",
       "      <td>Газпром</td>\n",
       "      <td>«Газпром» — глобальная энергетическая компания...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-08-20 09:37:02+00:00</td>\n",
       "      <td>Сегодня состоится последний визит в Москву Анг...</td>\n",
       "      <td>GAZP</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>Энергетика</td>\n",
       "      <td>Газпром</td>\n",
       "      <td>«Газпром» — глобальная энергетическая компания...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>2019-09-27 10:15:06+00:00</td>\n",
       "      <td>Новый глава Башкирии Радий Хабиров затевает во...</td>\n",
       "      <td>TATN</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2</td>\n",
       "      <td>Энергетика</td>\n",
       "      <td>Татнефть</td>\n",
       "      <td>Татнефть — одна из крупнейших российских нефтя...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2576</th>\n",
       "      <td>2020-12-25 06:00:06+00:00</td>\n",
       "      <td>Основные экономически события за 24 часа: ПАО ...</td>\n",
       "      <td>VTBR</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>Финансовый сектор</td>\n",
       "      <td>ВТБ</td>\n",
       "      <td>Банк ВТБ — второй банк по величине активов в Р...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>2020-12-25 06:00:06+00:00</td>\n",
       "      <td>Основные экономически события за 24 часа: ПАО ...</td>\n",
       "      <td>MTSS</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>Телекоммуникации</td>\n",
       "      <td>МТС</td>\n",
       "      <td>МТС — цифровая экосистема и ведущая компания в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>2021-09-14 18:59:13+00:00</td>\n",
       "      <td>Акции главных американских нефтяных мейджеров ...</td>\n",
       "      <td>LKOH</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2</td>\n",
       "      <td>Энергетика</td>\n",
       "      <td>ЛУКОЙЛ</td>\n",
       "      <td>ЛУКОЙЛ — одна из крупнейших нефтегазовых компа...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>2021-09-14 18:59:13+00:00</td>\n",
       "      <td>Акции главных американских нефтяных мейджеров ...</td>\n",
       "      <td>TATN</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2</td>\n",
       "      <td>Энергетика</td>\n",
       "      <td>Татнефть</td>\n",
       "      <td>Татнефть — одна из крупнейших российских нефтя...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2580 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           date  \\\n",
       "0     2021-11-26 13:42:34+00:00   \n",
       "1     2021-09-07 07:22:01+00:00   \n",
       "2     2021-08-27 20:59:11+00:00   \n",
       "3     2021-08-24 08:04:25+00:00   \n",
       "4     2021-08-20 09:37:02+00:00   \n",
       "...                         ...   \n",
       "2575  2019-09-27 10:15:06+00:00   \n",
       "2576  2020-12-25 06:00:06+00:00   \n",
       "2577  2020-12-25 06:00:06+00:00   \n",
       "2578  2021-09-14 18:59:13+00:00   \n",
       "2579  2021-09-14 18:59:13+00:00   \n",
       "\n",
       "                                                message ticker sentiment  \\\n",
       "0     А акции Новатэка так вообще смогли закрыть утр...   NVTK  Positive   \n",
       "1     Объем торгов за первые 10 мин наглядно демонст...   GAZP  Positive   \n",
       "2     Итак, на этой неделе акции Газпрома наконец-то...   GAZP  Positive   \n",
       "3     ​​Не один раз в этом году на всех уровнях я то...   GAZP  Positive   \n",
       "4     Сегодня состоится последний визит в Москву Анг...   GAZP  Positive   \n",
       "...                                                 ...    ...       ...   \n",
       "2575  Новый глава Башкирии Радий Хабиров затевает во...   TATN  Negative   \n",
       "2576  Основные экономически события за 24 часа: ПАО ...   VTBR   Neutral   \n",
       "2577  Основные экономически события за 24 часа: ПАО ...   MTSS   Neutral   \n",
       "2578  Акции главных американских нефтяных мейджеров ...   LKOH  Negative   \n",
       "2579  Акции главных американских нефтяных мейджеров ...   TATN  Negative   \n",
       "\n",
       "      label             sector      name  \\\n",
       "0         1         Энергетика   НОВАТЭК   \n",
       "1         1         Энергетика   Газпром   \n",
       "2         1         Энергетика   Газпром   \n",
       "3         1         Энергетика   Газпром   \n",
       "4         1         Энергетика   Газпром   \n",
       "...     ...                ...       ...   \n",
       "2575      2         Энергетика  Татнефть   \n",
       "2576      0  Финансовый сектор       ВТБ   \n",
       "2577      0   Телекоммуникации       МТС   \n",
       "2578      2         Энергетика    ЛУКОЙЛ   \n",
       "2579      2         Энергетика  Татнефть   \n",
       "\n",
       "                                               describe  \n",
       "0     НОВАТЭК — крупнейший независимый производитель...  \n",
       "1     «Газпром» — глобальная энергетическая компания...  \n",
       "2     «Газпром» — глобальная энергетическая компания...  \n",
       "3     «Газпром» — глобальная энергетическая компания...  \n",
       "4     «Газпром» — глобальная энергетическая компания...  \n",
       "...                                                 ...  \n",
       "2575  Татнефть — одна из крупнейших российских нефтя...  \n",
       "2576  Банк ВТБ — второй банк по величине активов в Р...  \n",
       "2577  МТС — цифровая экосистема и ведущая компания в...  \n",
       "2578  ЛУКОЙЛ — одна из крупнейших нефтегазовых компа...  \n",
       "2579  Татнефть — одна из крупнейших российских нефтя...  \n",
       "\n",
       "[2580 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(final_2)):\n",
    "    t = final_2['ticker'][index]\n",
    "    n = final_2['name'][index]\n",
    "    d = final_2['describe'][index]\n",
    "    s = final_2['sector'][index]\n",
    "    m = final_2['message'][index]\n",
    "    final_2.loc[index, \"message\"] = f'[{t}, {n}, {s}][SEP]{m}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[NVTK, НОВАТЭК, Энергетика][SEP]А акции Новатэка так вообще смогли закрыть утренний гэп на открытии. Не видно совсем паники в акциях российских \"газовиков\".'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_2[\"message\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_model_embed = tokenizer(final_2['message'].tolist(), padding=True, return_tensors='pt')\n",
    "\n",
    "text_code = torch.unsqueeze(tokens_model_embed['input_ids'], dim=1)\n",
    "masked = torch.unsqueeze(tokens_model_embed['attention_mask'], dim=1)\n",
    "Y_sep = torch.from_numpy(final_2['label'].to_numpy()).long()\n",
    "X_sep = torch.cat((text_code, masked), dim=1)\n",
    "\n",
    "INDEX = final_2.label.value_counts().min()\n",
    "\n",
    "torch.manual_seed(12312)\n",
    "y_negative_index = (Y_sep == 2).nonzero().reshape((-1))\n",
    "y_negative_index_rand = torch.randperm(y_negative_index.shape[0])\n",
    "y_negative_index = y_negative_index[y_negative_index_rand][:INDEX]\n",
    "torch.manual_seed(12312)\n",
    "y_positive_index = (Y_sep == 1).nonzero().reshape((-1))\n",
    "y_positive_index_rand = torch.randperm(y_positive_index.shape[0])\n",
    "y_positive_index = y_positive_index[y_positive_index_rand][:INDEX]\n",
    "torch.manual_seed(12312)\n",
    "y_neutral_index = (Y_sep == 0).nonzero().reshape((-1))\n",
    "y_neutral_index_rand = torch.randperm(y_neutral_index.shape[0])\n",
    "y_neutral_index = y_neutral_index[y_neutral_index_rand][:INDEX]\n",
    "\n",
    "X_sep = X_sep[torch.cat((y_negative_index, y_positive_index, y_neutral_index))]\n",
    "Y_sep = Y_sep[torch.cat((y_negative_index, y_positive_index, y_neutral_index))]\n",
    "\n",
    "x_train_sep, x_test_sep, y_train_sep, y_test_sep = train_test_split(X_sep, Y_sep, test_size=0.15, random_state=12312, shuffle=True)\n",
    "\n",
    "loader_train_final_2 = DataLoader(TensorDataset(x_train_sep, y_train_sep), batch_size=batch_size)\n",
    "loader_test_final_2 = DataLoader(TensorDataset(x_test_sep, y_test_sep), batch_size=batch_size)\n",
    "\n",
    "# weight_ce_cep = 1 / (y_train_sep.sum(dim=0) / y_train_sep.sum(dim=0).sum()) / (1 / (y_train_sep.sum(dim=0) / y_train_sep.sum(dim=0).sum())).sum()\n",
    "# weight_ce_cep = torch.tensor([0.3, 0.4, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model.gradient_checkpointing_enable()\n",
    "lr = 5e-5\n",
    "weight_decay = 1e-2\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "losser = nn.CrossEntropyLoss()\n",
    "scaler = torch.amp.GradScaler(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [01:51<00:00,  1.92s/it]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]c:\\Users\\Stanislav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 11/11 [00:04<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train loss:44.75699362158775, test loss:7.419869422912598, train accuracy: 0.6683, test accuracy: 0.7184, koef_train_test: 6.032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [01:54<00:00,  1.98s/it]\n",
      "100%|██████████| 11/11 [00:04<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, train loss:30.127362623810768, test loss:7.244628369808197, train accuracy: 0.7924, test accuracy: 0.7469, koef_train_test: 4.1586\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    stat_loss_train = 0\n",
    "    train_accuracy = 0\n",
    "    stat_loss_test = 0\n",
    "    test_accuracy = 0\n",
    "\n",
    "    for x, y in tqdm(loader_train_final_2):\n",
    "        optimizer.zero_grad()\n",
    "        text, mask, target = x[:, 0, :].to(device), x[:, 1, :].to(device), y.to(device)\n",
    "        with autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "            pred = model(text, attention_mask=mask).logits\n",
    "            loss = losser(pred, target)\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        train_accuracy += pred.argmax(dim=1).eq(target).sum().item()\n",
    "        stat_loss_train += loss.item()\n",
    "\n",
    "    for x, y in tqdm(loader_test_final_2):\n",
    "        text, mask, target = x[:, 0, :].to(device), x[:, 1, :].to(device), y.to(device)\n",
    "        with torch.no_grad(), autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "            pred = model(text, attention_mask=mask).logits\n",
    "            loss = losser(pred, target)\n",
    "            scaler.scale(loss)\n",
    "        stat_loss_test += loss.item()   \n",
    "        test_accuracy += pred.argmax(dim=1).eq(target).sum().item()\n",
    "\n",
    "    train_accuracy = train_accuracy / len(loader_train_final_2.dataset)\n",
    "    test_accuracy = test_accuracy / len(loader_test_final_2.dataset)  \n",
    "\n",
    "    print(f'Epoch: {epoch+1}', \n",
    "            f'train loss:{stat_loss_train}', \n",
    "            f'test loss:{stat_loss_test}', \n",
    "            f'train accuracy: {round(train_accuracy, 4)}', \n",
    "            f'test accuracy: {round(test_accuracy, 4)}', \n",
    "            f'koef_train_test: {round(stat_loss_train / stat_loss_test, 4)}',\n",
    "            sep=', ')\n",
    "    \n",
    "    torch.save(model, f'{model_name}/222_mt5_fin2_{round(test_accuracy, 4)}_{round(train_accuracy, 4)}_epoch_{epoch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mt-cleaned-labeled5.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>channel_url</th>\n",
       "      <th>date</th>\n",
       "      <th>message</th>\n",
       "      <th>views</th>\n",
       "      <th>forwards</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://t.me/markettwits</td>\n",
       "      <td>2022-04-06 11:52:33+00:00</td>\n",
       "      <td>Япония снимет ограничения на въезд для 106 стр...</td>\n",
       "      <td>5117.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>https://t.me/markettwits</td>\n",
       "      <td>2022-04-06 09:54:15+00:00</td>\n",
       "      <td>Китай - госкомпании выкупают активы проблемных...</td>\n",
       "      <td>35066.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108</td>\n",
       "      <td>https://t.me/markettwits</td>\n",
       "      <td>2022-04-06 04:40:10+00:00</td>\n",
       "      <td>ВОЗ сообщила о снижении на 43% смертности от к...</td>\n",
       "      <td>39175.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149</td>\n",
       "      <td>https://t.me/markettwits</td>\n",
       "      <td>2022-04-05 16:06:32+00:00</td>\n",
       "      <td>iRemit (партнер Ripple, использует Ripple ODL)...</td>\n",
       "      <td>54555.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>164</td>\n",
       "      <td>https://t.me/markettwits</td>\n",
       "      <td>2022-04-05 14:48:52+00:00</td>\n",
       "      <td>сд Позитив рекомендовал дивиденды 1кв 2022г = ...</td>\n",
       "      <td>52335.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88322</th>\n",
       "      <td>94039</td>\n",
       "      <td>https://t.me/markettwits</td>\n",
       "      <td>2018-01-18 06:57:04+00:00</td>\n",
       "      <td>НЕФТЬ - DUMB MONEY - COT data Хедж-фонды на би...</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88323</th>\n",
       "      <td>94406</td>\n",
       "      <td>https://t.me/markettwits</td>\n",
       "      <td>2018-01-11 05:06:39+00:00</td>\n",
       "      <td>КРИПТО - РЕГУЛИРОВАНИЕ - Ю.КОРЕЯ Reuters пишет...</td>\n",
       "      <td>859.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88324</th>\n",
       "      <td>94430</td>\n",
       "      <td>https://t.me/markettwits</td>\n",
       "      <td>2018-01-10 15:37:45+00:00</td>\n",
       "      <td>КРИПТО - МАЙНИНГ - КИТАЙ CHINA QUIETLY ORDERS ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88325</th>\n",
       "      <td>94436</td>\n",
       "      <td>https://t.me/markettwits</td>\n",
       "      <td>2018-01-10 14:54:11+00:00</td>\n",
       "      <td>КИТАЙ - США - БОНДЫ GROSS: RECENT EVIDENCE SHO...</td>\n",
       "      <td>954.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88326</th>\n",
       "      <td>94439</td>\n",
       "      <td>https://t.me/markettwits</td>\n",
       "      <td>2018-01-10 14:31:41+00:00</td>\n",
       "      <td>КРИПТО - МАЙНИНГ - КИТАЙ CHINA QUIETLY ORDERS ...</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88327 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         idx               channel_url                       date  \\\n",
       "0          1  https://t.me/markettwits  2022-04-06 11:52:33+00:00   \n",
       "1         31  https://t.me/markettwits  2022-04-06 09:54:15+00:00   \n",
       "2        108  https://t.me/markettwits  2022-04-06 04:40:10+00:00   \n",
       "3        149  https://t.me/markettwits  2022-04-05 16:06:32+00:00   \n",
       "4        164  https://t.me/markettwits  2022-04-05 14:48:52+00:00   \n",
       "...      ...                       ...                        ...   \n",
       "88322  94039  https://t.me/markettwits  2018-01-18 06:57:04+00:00   \n",
       "88323  94406  https://t.me/markettwits  2018-01-11 05:06:39+00:00   \n",
       "88324  94430  https://t.me/markettwits  2018-01-10 15:37:45+00:00   \n",
       "88325  94436  https://t.me/markettwits  2018-01-10 14:54:11+00:00   \n",
       "88326  94439  https://t.me/markettwits  2018-01-10 14:31:41+00:00   \n",
       "\n",
       "                                                 message    views  forwards  \\\n",
       "0      Япония снимет ограничения на въезд для 106 стр...   5117.0       1.0   \n",
       "1      Китай - госкомпании выкупают активы проблемных...  35066.0       1.0   \n",
       "2      ВОЗ сообщила о снижении на 43% смертности от к...  39175.0      38.0   \n",
       "3      iRemit (партнер Ripple, использует Ripple ODL)...  54555.0      47.0   \n",
       "4      сд Позитив рекомендовал дивиденды 1кв 2022г = ...  52335.0     123.0   \n",
       "...                                                  ...      ...       ...   \n",
       "88322  НЕФТЬ - DUMB MONEY - COT data Хедж-фонды на би...   1056.0       0.0   \n",
       "88323  КРИПТО - РЕГУЛИРОВАНИЕ - Ю.КОРЕЯ Reuters пишет...    859.0       0.0   \n",
       "88324  КРИПТО - МАЙНИНГ - КИТАЙ CHINA QUIETLY ORDERS ...      5.0       0.0   \n",
       "88325  КИТАЙ - США - БОНДЫ GROSS: RECENT EVIDENCE SHO...    954.0       0.0   \n",
       "88326  КРИПТО - МАЙНИНГ - КИТАЙ CHINA QUIETLY ORDERS ...   1964.0       0.0   \n",
       "\n",
       "       label  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "88322      2  \n",
       "88323      2  \n",
       "88324      2  \n",
       "88325      2  \n",
       "88326      2  \n",
       "\n",
       "[88327 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_cleandet_labeled5 = pd.read_csv(\"data/mt-cleaned-labeled5.csv\")#.drop(columns=[\"idx\", \"channel_url\", \"views\", \"forwards\"])\n",
    "mt_cleandet_labeled5[\"label\"] = mt_cleandet_labeled5[\"label\"].apply(lambda row: 2 if row == -1 else row)\n",
    "mt_cleandet_labeled5.drop_duplicates(inplace=True)\n",
    "mt_cleandet_labeled5.dropna(inplace=True)\n",
    "mt_cleandet_labeled5.reset_index(inplace=True, drop=True)\n",
    "mt_cleandet_labeled5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mins_sample = mt_cleandet_labeled5.label.value_counts().min()\n",
    "mt_cleandet_labeled5 = mt_cleandet_labeled5.groupby(by='label', group_keys=False).apply(lambda x: x.sample(mins_sample, random_state=12312))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Stanislav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2691: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokens_model_embed_1 = tokenizer(mt_cleandet_labeled5['message'].tolist(), padding=True, return_tensors='pt', max_length=1536)\n",
    "\n",
    "text_code = torch.unsqueeze(tokens_model_embed_1['input_ids'], dim=1)\n",
    "masked = torch.unsqueeze(tokens_model_embed_1['attention_mask'], dim=1)\n",
    "Y_news = torch.from_numpy(mt_cleandet_labeled5[['label']].to_numpy()).long().reshape(-1)\n",
    "X_news = torch.cat((text_code, masked), dim=1)\n",
    "\n",
    "x_train_news, x_test_news, y_train_news, y_test_news = train_test_split(X_news, Y_news, test_size=0.15, random_state=12312, shuffle=True)\n",
    "\n",
    "loader_train_mt_cleandet_labeled5 = DataLoader(TensorDataset(x_train_news, y_train_news), batch_size=batch_size)\n",
    "loader_test_mt_cleandet_labeled5 = DataLoader(TensorDataset(x_test_news, y_test_news), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model.gradient_checkpointing_enable()\n",
    "lr = 3e-5\n",
    "weight_decay = 1e-2\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "losser = nn.CrossEntropyLoss()\n",
    "scaler = torch.amp.GradScaler(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1716/1716 [24:00<00:00,  1.19it/s]\n",
      "  0%|          | 0/303 [00:00<?, ?it/s]c:\\Users\\Stanislav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 303/303 [00:57<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train loss:1123.221481487155, test loss:167.85613371431828, train accuracy: 0.7197, test accuracy: 0.7744, koef_train_test: 6.6916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1716/1716 [22:43<00:00,  1.26it/s]\n",
      "100%|██████████| 303/303 [00:52<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, train loss:783.0999687686563, test loss:168.4883097782731, train accuracy: 0.8172, test accuracy: 0.7895, koef_train_test: 4.6478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/1716 [00:13<23:47,  1.19it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model(text, attention_mask\u001b[38;5;241m=\u001b[39mmask)\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m losser(pred, target)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m     17\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n",
      "File \u001b[1;32mc:\\Users\\Stanislav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Stanislav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Stanislav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    stat_loss_train = 0\n",
    "    train_accuracy = 0\n",
    "    stat_loss_test = 0\n",
    "    test_accuracy = 0\n",
    "\n",
    "    for x, y in tqdm(loader_train_mt_cleandet_labeled5):\n",
    "        optimizer.zero_grad()\n",
    "        text, mask, target = x[:, 0, :].to(device), x[:, 1, :].to(device), y.to(device)\n",
    "        with autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "            pred = model(text, attention_mask=mask).logits\n",
    "            loss = losser(pred, target)\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        train_accuracy += pred.argmax(dim=1).eq(target).sum().item()\n",
    "        stat_loss_train += loss.item()\n",
    "\n",
    "    for x, y in tqdm(loader_test_mt_cleandet_labeled5):\n",
    "        text, mask, target = x[:, 0, :].to(device), x[:, 1, :].to(device), y.to(device)\n",
    "        with torch.no_grad(), autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "            pred = model(text, attention_mask=mask).logits\n",
    "            loss = losser(pred, target)\n",
    "        scaler.scale(loss)\n",
    "        stat_loss_test += loss.item()   \n",
    "        test_accuracy += pred.argmax(dim=1).eq(target).sum().item()\n",
    "\n",
    "    train_accuracy = train_accuracy / len(loader_train_mt_cleandet_labeled5.dataset)\n",
    "    test_accuracy = test_accuracy / len(loader_test_mt_cleandet_labeled5.dataset)  \n",
    "\n",
    "    print(f'Epoch: {epoch+1}', \n",
    "            f'train loss:{stat_loss_train}', \n",
    "            f'test loss:{stat_loss_test}', \n",
    "            f'train accuracy: {round(train_accuracy, 4)}', \n",
    "            f'test accuracy: {round(test_accuracy, 4)}', \n",
    "            f'koef_train_test: {round(stat_loss_train / stat_loss_test, 4)}',\n",
    "            sep=', ')\n",
    "    \n",
    "    torch.save(model, f'{model_name}/mt5_context-100_{round(test_accuracy, 4)}_{round(train_accuracy, 4)}_epoch_{epoch}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
